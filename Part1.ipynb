{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 Web scraping and buliding the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 1: Using api to scrap data from api.bilibili.com\n",
    "\n",
    "- In this step we will use `get` method, `api` and `multiprocess` in coding\n",
    "    - `get` is to request and get data from a certain website\n",
    "    - `api` is the interface or port for develppers and website to get data\n",
    "    - `multiprocess` is a technique to do multi tasks at the same tiem without waiting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Libs used in this part__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import bs4\n",
    "import lxml.etree as xml\n",
    "import json\n",
    "import time\n",
    "import csv\n",
    "import threading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spider function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spider_0 (url,filename):\n",
    "    \n",
    "    r = requests.get(url)\n",
    "    \n",
    "    data = json.dumps(r.json())\n",
    "\n",
    "    file = open(filename, 'w')\n",
    "\n",
    "    file.write(data)\n",
    "\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping function using multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cuky = {\"cookie\":\"a7e650d9%2C1682628083%2C7a5b8%2Aa2\"}\n",
    "url = \"http://api.bilibili.com/x/web-interface/view/detail?aid={}\"  \n",
    "loc = 'test_data_160000/{}.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start=time.time()\n",
    "\n",
    "start = 160000\n",
    "\n",
    "end = 165000\n",
    "\n",
    "threads = []\n",
    "\n",
    "for i in range (start,end):\n",
    "    \n",
    "    threads.append(threading.Thread(target=spider_0, args=(url.format(str(i)),loc.format(str(i)))))\n",
    "    \n",
    "for thread in threads:\n",
    "    \n",
    "    thread.start()\n",
    "    \n",
    "for thread in threads:\n",
    "    \n",
    "    thread.join()\n",
    "    \n",
    "    \n",
    "time_use = time.time() - time_start\n",
    "print(\"data:\"+str(start)+\" : \" + str(end))\n",
    "print(\"time use: \" + str(time_use))\n",
    "print(\"ave: \"+ str(time_use/(end-start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 analyze the data structure and bulid the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using 170001 as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test_data_160000/170001.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\File\\cs216-project\\Part1.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/File/cs216-project/Part1.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url\u001b[39m.\u001b[39mformat(\u001b[39mstr\u001b[39m(\u001b[39m170001\u001b[39m)))\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/File/cs216-project/Part1.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m download \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mdumps(data\u001b[39m.\u001b[39mjson())\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/File/cs216-project/Part1.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m file \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(loc\u001b[39m.\u001b[39;49mformat(\u001b[39mstr\u001b[39;49m(\u001b[39m170001\u001b[39;49m)), \u001b[39m'\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/File/cs216-project/Part1.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m file\u001b[39m.\u001b[39mwrite(download)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/File/cs216-project/Part1.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m file\u001b[39m.\u001b[39mclose()\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test_data_160000/170001.json'"
     ]
    }
   ],
   "source": [
    "data = requests.get(url.format(str(170001)))\n",
    "\n",
    "download = json.dumps(data.json())\n",
    "\n",
    "file = open(loc.format(str(170001)), 'w')\n",
    "\n",
    "file.write(download)\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 这里我已经给你们下好了，如果不小心删掉了就直接用上面的代码运行一下就ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discourt the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"170001.json\", encoding=\"gbk\") as f:\n",
    "    labels = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discourt(labels):\n",
    "    \n",
    "    datas = labels[\"data\"]\n",
    "    for data in datas:\n",
    "        print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if labels[\"code\"] == 0:\n",
    "    discourt(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### These dictionaries like Tags, View and Card are the things that we need to put into different csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take Tags as example to analyze the json file and build data base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = labels[\"data\"][\"Tags\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We use dictionary from a part of json file as input, just like I show above, if I only need to analyze Tags, I use sub dictionary 'tags' as imput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "aid = '170001'\n",
    "\n",
    "\n",
    "myFile = open('170001.csv', 'w')\n",
    "\n",
    "writer = csv.writer(myFile)\n",
    "writer.writerow(['aid','tag_id', 'tag_name', 'cover','head_cover','content','short_content',\n",
    "                 'type','state','ctime','count','is_atten','likes','hates','attribute',\n",
    "                 'liked','hated','extra_attr','music_id','tag_type','is_activity','color',\n",
    "                 'alpha','is_season','subscribed_count','archive_count','featured_count',\n",
    "                 'jump_url'])\n",
    "for tag in tags:\n",
    "    \n",
    "    writer.writerow([aid,tag.values()])\n",
    "    \n",
    "myFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to check if you create things right? Use this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myFile = open('170001.csv', 'r')\n",
    "\n",
    "print(\"The content of the csv file is:\")\n",
    "print(myFile.read())\n",
    "\n",
    "myFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What you need to do:\n",
    "\n",
    "- Create different functions for different sub-dictionaries and turn them into csv file.\n",
    "- Your function will excute once per josn file, whcih means the function will be use in a loop\n",
    "- The output of function should be \"create/add\" what's in the json file to the csv file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
